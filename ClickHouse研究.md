# ClickHouse研究

## 1. 为什么选型?

### 需要用5W1H描述清楚

> **5W 1H **
>
> 问题和解决方案说明，提出问题、分析问题、解决问题、后续计划
>
> 好的，把GA查询慢和数仓建设的问题说清楚，把解决方案的制定、落地实现和遇到的问题都讲清楚
>
> 数仓的部分可以再丰富下
>
> 查询慢的解决方案，每个改进的效果写清楚
>
>
> 逻辑 -  解决方案   - 设计    - 结果    - 优化   - 对比   -  量化
>
> 体现出 逻辑能力  设计能力  优化落地能力   突出重点







> https://www.jianshu.com/p/43ef12e16181?utm_campaign=haruki
>
> * ClickHouse原理层
>
> ClickHouse从OLAP场景需求出发，定制开发了一套全新的高效列式存储引擎，并且实现了数据有序存储、主键索引、稀疏索引、数据Sharding、数据Partitioning、TTL、主备复制等丰富功能。以上功能共同为ClickHouse极速的分析性能奠定了基础。
>
> * ClickHouse写入层
>
> ClickHouse采用类LSM Tree的结构，数据写入后定期在后台Compaction。通过类LSM tree的结构，ClickHouse在数据导入时全部是顺序append写，写入后数据段不可更改，在后台compaction时也是多个段merge sort后顺序写回磁盘。顺序写的特性，充分利用了磁盘的吞吐能力，即便在HDD上也有着优异的写入性能。
>
> * ClickHouse计算层
>
> ClickHouse在计算层做了非常细致的工作，竭尽所能榨干硬件能力，提升查询速度。它实现了单机多核并行、分布式计算、向量化执行与SIMD指令、代码生成等多种重要技术。  **动态代码生成Runtime Codegen**
>
> ClickHouse更是一整套完善的解决方案，它自包含了存储和计算能力（无需额外依赖其他存储组件），完全自主实现了高可用，而且支持完整的SQL语法包括JOIN等，技术上有着明显优势。相比于hadoop体系，以数据库的方式来做大数据处理更加简单易用，学习成本低且灵活度高。
>
> **特性：**
>
> - 基于shard+replica实现的线性扩展和高可靠
> - 稀疏索引 , 采用列式存储，数据类型一致，压缩性能更高
> - 硬件利用率高，连续IO，提高了磁盘驱动器的效率
> - 向量化引擎与SIMD提高了CPU利用率，多核多节点并行化大查询
>
> **不足：**
>
> - 不支持事务、异步删除与更新
> - 不适用高并发场景
>
> 



### 1.1 列式存储

#### Parquet

>  https://zhuanlan.zhihu.com/p/111822325

一个Parquet文件的内容由Header、Data Block和Footer三部分组成。在文件的首尾各有一个内容为PAR1的Magic Number，用于标识这个文件为Parquet文件。Header部分就是开头的Magic Number。

Data Block是具体存放数据的区域，由多个Row Group组成，每个Row Group包含了一批数据。比如，假设一个文件有1000行数据，按照相应大小切分成了两个Row Group，每个拥有500行数据。每个Row Group中，数据按列汇集存放，每列的所有数据组合成一个Column Chunk。因此一个Row Group由多个Column Chunk组成，Column Chunk的个数等于列数。每个Column Chunk中，数据按照Page为最小单元来存储，根据内容分为Data Page和Dictionary Page。这样逐层设计的目的在于：

- 多个Row Group可以实现数据的并行加
- 不同Column Chunk用来实现列存储
- 进一步分割成Page，可以实现更细粒度的数据访问

### 列式存储压缩算法

> https://www.cnblogs.com/23lalala/p/5643541.html

* **字典编码**

利用数据类型的一致性，将相同的值提取出来生成符号表，每个列值则直接存储该值映射成的符号表值id即可。

* **常量编码**

当区内的数据大部分的数据相同，只有少数不同时，可以采用常量编码。该编码将区内数据出现最多的一个值作为常量值，其他值作为异常值。异常值使用<行号+值>的方式存储。

* **RLE编码**

当区内的数据存在大量的相同值，每个不同值的个数比较均匀，且连续出现时，可以使用RLE编码。

* **序列编码**

当区内的数据差值成等差数列，或者存在一定的代数关系，则可以使用序列编码

> 字典编码、常量编码和RLE编码都是基于重复值较多的情况下使用的，如果不同值中，某个值出现多次，其他的值都只出现一次，则可以使用常量编码；如果这些不同值都连续出现多次，且出现的次数相当，则使用RLE编码；如果这些不同值出现的次数相当，但都不连续，则使用字典编码。从上可知，这三种编码方式都是基于不同值的分布特征来确定使用哪种编码，也就是说，只会使用三种中的一种编码方式，不会嵌套使用。
>
> 序列编码基于前后两个数据的差值大部分都相同的一种编码方式，当差值计算出来之后，可以再分析其数据特征确定再使用前面三种编码方式。
>
> 综上所述，这四种编码策略如下：
>
> 1. 如果该列为自增列或序列，则直接使用序列编码；
> 2. 获得区数据统计信息：不同值个数n_dist、每个不同值个数、不同值数据指针、每个值连续出现的次数、整型数的最大值；
> 3. 根据获得的区统计信息，确定使用常量编码、RLE编码还是字典编码；这三种编码的使用顺序为：优先使用常量编码，其次使用RLE编码，最后才使用字典编码。
> 4. 如果编码后的总长度超过了原始长度，则不编码，直接返回；

### 1.2 向量化执行

**矢量化是将标量程序转换成矢量程序的术语。向量化程序可以从一条指令中运行多个操作，而标量只能同时对一对操作数进行操作。**

标量法：

```js
for (i = 0; i < 1024; i++){
   C[i] = A[i]*B[i];
}
```

矢量化方法：

```js
for (i = 0; i < 1024; i+=4){
   C[i:i+3] = A[i:i+3]*B[i:i+3];
}
```

## 2、写原理与优化





## 3、读原理与优化



## 4、表结构优化

### 4.1、 低基数类型

> https://www.jianshu.com/p/f361e7cfc8b3



## 5、注意事项

1. **数据写入**

- 一个batch内不要写多个分区的数据；
- 根据服务器配置适当增大background_pool_size，提高merge线程的数量 默认值16；
- 对于system.merges、system.processes表做好监控，可随时感知写入压力情况作出预警，避免服务崩溃；
- 索引不宜建立过多，对于大数据量高并发的写入可以考虑先做数据编排按建表索引排序在写入，减少merge压力；
- 禁止对Distributed表写入，可通过代理方式如nginx或chproxy直接对local表写入，而且能基于配置实现均衡写入及动态上下线节点。

1. **JOIN操作**

- 无论什么join小表必须放在右边，可以用left、right调整join方式；
- 开启谓词下推：enable_optimize_predicate_expression=1(部分版本默认关闭)；
- 大量降低数据量的操作如where、group by、distinct操作优先在join之前做(需根据降低比例评估)。

1. **常用参数**

- max_execution_time 单次查询的最大时间：600s；
- max_memory_usage 单服务器单次查询使用的最大内存，设置总体内存的50%；
- max_bytes_before_external_group_by 启动外部存储 max_memory_usage/2；
- max_memory_usage_for_all_queries 单服务器所有查询使用的最大内存，设置总体内存的80%-90%，防止因clickhouse服务占用过大资源导致服务器假死。